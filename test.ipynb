{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src.models.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdiffusion_module\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LightningDiffusionModule, DiffusionModel\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTwoResUnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TwoResUNet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Bureau/Projects/DiffusionModel_from_scratch/src/models/diffusion_module.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_lightning\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpl\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mTwoResUnet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TwoResUNet\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m \n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'src.models.models'"
     ]
    }
   ],
   "source": [
    "from src.models.diffusion_module import LightningDiffusionModule, DiffusionModel\n",
    "from src.models.TwoResUnet import TwoResUNet\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model= TwoResUNet(dim = 64)\n",
    "diff_model = DiffusionModel(model = model)\n",
    "light_module = LightningDiffusionModule(model=diff_model,  wandb_flag = False)\n",
    "checkpoint = torch.load(\"results/classic/diffusion_model-epoch=139-train_loss=0.00.ckpt\")\n",
    "print(checkpoint)\n",
    "light_module.on_load_checkpoint(checkpoint=checkpoint)\n",
    "light_module = light_module\n",
    "print(light_module.diff_model)\n",
    "light_module.diff_model.eval()\n",
    "\n",
    "image = light_module.diff_model.p_sample_loop((1,3,64,64))\n",
    "\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes for better display\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exported to results/onnx/diffusion_model.onnx\n"
     ]
    }
   ],
   "source": [
    "onnx_path = \"results/onnx/diffusion_model.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    light_module.diff_model.diffusion_model,       # The model being converted\n",
    "    (dummy_input,dummy_t),                   # Example input to trace the model\n",
    "    onnx_path,                     # Path to save the ONNX file\n",
    "    export_params=True,            # Store the trained parameters in the model file\n",
    "    opset_version=11,              # ONNX version to export the model to\n",
    "    do_constant_folding=True,      # Whether to execute constant folding for optimization\n",
    "    input_names=['input', 'time'],         # Model input names\n",
    "    output_names=['output'],       # Model output names\n",
    "    dynamic_axes={'input': {0: 'batch_size'}, 'output': {0: 'batch_size'}, 'time': {0: 'batch_size'}}  # Variable length axes\n",
    ")\n",
    "\n",
    "print(f\"Model exported to {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Please consider to run pre-processing before quantization. Refer to example: https://github.com/microsoft/onnxruntime-inference-examples/blob/main/quantization/image_classification/cpu/ReadMe.md \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantized model saved to results/onnx/diffusion_model_quantized.onnx\n"
     ]
    }
   ],
   "source": [
    "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
    "\n",
    "quantized_model_path = \"results/onnx/diffusion_model_quantized.onnx\"\n",
    "\n",
    "quantize_dynamic(\n",
    "    model_input=onnx_path,                # Input ONNX model path\n",
    "    model_output=quantized_model_path,    # Output quantized model path\n",
    "    op_types_to_quantize=['Matmul'],  # Operations to quantize (you can customize this list)\n",
    "    per_channel=True,                     # Enable per-channel quantization\n",
    "    reduce_range=True,                    # Reduce the range of quantized values\n",
    "    weight_type=QuantType.QInt8           # Quantization type (can also be QuantType.QUInt8)\n",
    ")\n",
    "\n",
    "print(f\"Quantized model saved to {quantized_model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime as ort\n",
    "\n",
    "# Load the quantized model\n",
    "ort_session = ort.InferenceSession(quantized_model_path)\n",
    "\n",
    "# # Run inference\n",
    "# outputs = ort_session.run(None, {\"input\": dummy_input.cpu().numpy()})\n",
    "\n",
    "# for input in ort_session.get_inputs():\n",
    "#     print(f\"Input Name: {input.name}, Shape: {input.shape}\")\n",
    "# print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(arr, t, shape):\n",
    "    batch_size = shape[0]\n",
    "    out = np.take(arr, t)\n",
    "    out = np.reshape(out, (1,) * (len(shape) - 1))  # Reshape to match the number of dimensions except batch size\n",
    "    return np.broadcast_to(out, shape)\n",
    "\n",
    "\n",
    "def p_sample(ort_session, x, t, betas, sqrt_recip_alphas, sqrt_one_minus_alphas_cumprod, posterior_variance):\n",
    "    t = np.array([t], dtype=np.int64)\n",
    "    preds = ort_session.run(None, {\"input\": x.cpu().numpy(), \"time\": t})[0]\n",
    "    betas_t = extract(betas, t, x.shape)\n",
    "    sqrt_recip_alphas_t = extract(sqrt_recip_alphas, t, x.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x.shape)\n",
    "\n",
    "    predicted_mean = sqrt_recip_alphas_t * (x.cpu().numpy() - betas_t * preds / sqrt_one_minus_alphas_cumprod_t)\n",
    "\n",
    "    if t == 0:\n",
    "        return predicted_mean\n",
    "    else:\n",
    "        posterior_variance_t = extract(posterior_variance, t, x.shape)\n",
    "        noise = np.random.randn(*x.shape).astype(np.float32)\n",
    "        return predicted_mean + np.sqrt(posterior_variance_t) * noise\n",
    "\n",
    "\n",
    "def p_sample_loop(ort_session, shape, betas, sqrt_recip_alphas, sqrt_one_minus_alphas_cumprod, posterior_variance, num_timesteps):\n",
    "    \n",
    "    img = np.random.randn(*shape).astype(np.float32)\n",
    "\n",
    "    for t in tqdm(reversed(range(num_timesteps)), total=num_timesteps):\n",
    "        img = p_sample(ort_session, torch.tensor(img), t, betas, sqrt_recip_alphas, sqrt_one_minus_alphas_cumprod, posterior_variance)\n",
    "    \n",
    "    return torch.tensor(img).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:25<00:00, 39.13it/s]\n",
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZ9UlEQVR4nO3deZTddXnH8efeO3f2LbNkJglZyJ4YQhK2QCABXChuKAoq1kItoNZjUc+p9FS7W9tT8RzbShW0Wo5UBS0qUBYxFYgsSRACIXsmk2Qms2b29c5dfv3vqed8P78SkJCF9+vPz/lm5uZmcj5zz+85zzcRRVFkAACYWfJEvwAAwMmDUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgCs60S8AeH0UguT+R38sTz6+5QGZR9m0/tL5YhlnChNBVpRvlGc/+4lPynz+gkX6ewInCJ8UAACOUgAAOEoBAOAoBQCA40EzTilDI4Myv/27fxZkO1/aKM8uP2+WzAvhs2ozMyst1g+g62aWB9m3b9sqz6Y+/Wn9xYGTDJ8UAACOUgAAOEoBAOAoBQCAoxQAAI7pI5yUsvlJmd/5g7+R+f6Wh4Ns3VsXy7O5fE7m+UJe5olI57ls+N+nUJiSZ0tKSmQOnGz4pAAAcJQCAMBRCgAARykAABylAABwTB/hhMpmMzK/695vy3xg4CmZX7JhSZCNT+opo3RK/y6USurlR4W8nj7K57JBVlmj9yQlxCVAwMmITwoAAEcpAAAcpQAAcJQCAMBRCgAAl4iiKDrRLwKnm3Aqx8zsme33BNmBgR3ybPf+52Q+f26pzNNit1AykZBnM5P69R09OiTz8TE9IZXLhlNJVWXT5NmOw+EtbWZmf/Wl+2QOnCh8UgAAOEoBAOAoBQCAoxQAAI41F3jd7WnZLPPhzCNBtmZOmTybaZ4T89X17zGRhfMScTMU+ZzOi4v0g+nW1q6Y1xJ+nczEiDxZXjQe8zXi1l/w+xpODH7yAACOUgAAOEoBAOAoBQCAoxQAAI7pI7xmE+M9Mu+buEvmi88MVz2MDKfk2URaX2xjMRNFiUj8fhO3wCUmb2zUKyqiKT051HqgLzxbmIz5nvr3r4GubplPa56hvw5wnPFJAQDgKAUAgKMUAACOUgAAOEoBAOC4ZAevWUtreGmOmVlJ3eMyH58Is6lszO6fgs5jB4rEdE9xzNnRXLXMR1IrZN4/Gk4ZmZl1v3B/kCUmR+XZnkNHZF6aepfMb/3bO0XK73A4/vgpAwA4SgEA4CgFAICjFAAAjlIAADh2H+EV7Tv8kMzT0zbJvFDIynxyNJwdSpfq286iZMztaEk9lVTV3x5kd/RukGcP5Ktk3lm3UOZnj+mdSPMtE2SVxVPybLJZ/1fLDj8s8517vh5ky5d8Xp4FXk98UgAAOEoBAOAoBQCAoxQAAI5SAAA4po/wypIHdJwYknkqVyLzoc1lQdZ8QU5/z0r9tdNT+vxEIbzBrTzTKs/OjCplvuboszI/OLla5laxKIhmpH8jj3aPj8m8q/o8mXf2NQTZcv0qgNcVnxQAAI5SAAA4SgEA4CgFAIDjQTNe0UD3LJnXZfWPT1WtXlFRYjOCbOzBcD2FmVn51f0yT+itGLa7M3wtibZhefbCtH6g3NhUIfN509IynxoJV2401emH7NmJ8EG4mdnLu2fLfNHcS2UOHG98UgAAOEoBAOAoBQCAoxQAAI5SAAA4po/wikrL9FqIoY5wFYOZWUN1n8znnH80yMZb9PecykzIPFVRLPO23uogW9CoV2U0VOkpoyipf0eqz+kXmS0OJ40GM/pr7+leK/NzV71b5nNmzZE5cLzxSQEA4CgFAICjFAAAjlIAADhKAQDgmD7CK1q5/G0y3/38FplHeT05ZPlwJ1L1Yn20ezLcK2RmscuPamw8yBYumpRnM1m9y2hcDytZZHriKZUI//sMDuodRwcO6h1Ht/zJVfqbAicInxQAAI5SAAA4SgEA4CgFAICjFAAAjukjHAM98ZOMYm4ky+h8MpsNstERPSFkZXr6qJDTt7rVVuWDrLdXf42du/TXmL9QTw6Vp/V/k6gQ7j5KFunfs2qq9f6ouPcWOFH4pAAAcJQCAMBRCgAARykAABylAABwTB/hNats+qDM9+y5W+Y9gy8EWWl6TJ6tqc3JfGhALyh6eWc4OTTQp7/Gqov0xE92vEbmv3qhXOaT4+F/nyNt4YSVmdlt//JZmQMnGz4pAAAcpQAAcJQCAMBRCgAAx4NmvKKooB/YptP68pn/um+XzIeP9gfZqrP17yULV+mLenr79WspbwgfHs+av1CerWmaJfMdL3bJ/NH/6ZD55Fh4sU82G67bMDP7iy99QeZXvOMdMn/v+64LsnQR/11x/PFJAQDgKAUAgKMUAACOUgAAOEoBAOASURTpG0fwpjM8PCDzl3e8LPM7bv+azIf62mX+lrl1QTaQ0WsuzloTnjUzy2TDi23MzCbGwot91px3rjx70UU3yHznnj0yLxT0WozyinD9RTY7Jc9+784vy7yj54jMN1x0ZZDd/MlbY15H3AU+wKvHJwUAgKMUAACOUgAAOEoBAOAoBQCAY/roTWp0ZDjIbv/G38mzm7duk3lDzNDL9Gr9u0ZJUTgh1D88KM9e96kvyXzp4lX6m0bhXqCyyip5tKhITzAdT1MT4d4nM7Ntj3xF5ps2/jLI2iZmyLP/8I2fyLysrOIYXx3wf/ikAABwlAIAwFEKAABHKQAAHKUAAHBc5fQm1X+0N8hGR/rk2TUr9dTLOatXy/zZjQ/JvJAoBFl5aak821zfKPOq6gaZWyKlQn32BCgu07uczn+/3olUWxkOBW58Zos8e9+P7pb5ez/wYZlXVdfIHDDjkwIA4LdQCgAARykAABylAABwPGh+k9q0KVyjUJzWPw4XX7JC5nue3y7zoqR66GtWXFIcZFddc7M8O/vMt8jcEqfq7zEZmfa2PSHzXD68rOfa96+VZ//9nsd0/s02mV/94RtlPmfuPJnjzeVU/R8GADgOKAUAgKMUAACOUgAAOEoBAOCYPjrNtbcflnnb4d1BtuGy+fLskQOtMh/tCVdlmJlVVOjLXS664vogW7n2CnnWEuGFPKeEKLy8yMxs1yZ9mU5q6JDMa5qnBdm06bXy7Lr5+nu29XfIfPPTT8qc6SOY8UkBAPBbKAUAgKMUAACOUgAAOEoBAOCYPjrN/fynP5L5hkuag6yvV0+rjAwMyTwbs4fo0ivDKSMzs/MvfleQJU3vSTILL5n5//PjeaFOuIfIzGx8qCvIdj7z1/Ls9Gq9+yhRp9/DqBCeP7Rzvzw7kCuR+dHEEZmPt9wj80OHwt1Kc+culmdx+uKTAgDAUQoAAEcpAAAcpQAAcJQCAMAxfXSa6+zWE0XJbDj1MzrYJ88Oj+VlvqVlROYfmrVE5gkxOZTL6amcZEJPGXXsf1bmY+MHg2zJ6mvlWbNymU6NhtNEZmYtL/6nzNt/c3eQNVX2y7OD48tkPjmhp6/KSwtBNjyi36v+SRnbp65ZJPPenqMyf/Cx24Ps+htuk2fTRafobiq8Ij4pAAAcpQAAcJQCAMBRCgAARykAABzTR6eNcFrFzKytvV3mk6PhzV657Jg827WvRebFiSaZH2jdJ/NIDBRteUbfApbr3Svz6omNOp8WTvGMHNG3mo3ZTJk/8ciPZb60eofMly2oCbJpFXqa6PHn9Wt55Gm9s2nFwnC6p7xM76D66A0bZD4+pnc21VTrm/EWlD0XZN/45j/Ks5/7zF/IHKc+PikAABylAABwlAIAwFEKAACXiCL1+A+nHr2K4uabPy7zpmnhSosZtfpB5ttX1sp887ZOmWcr6mVely4OsgX1ekdDUVo/JM1O6ddYKIQXzTy7IyvPrloxXeap4edl3j1cJfMjPXVBtnqWflifTOdkvq0l/BpmZnXV4YPp+ga9WmLNpetkXkjpy3cKef2z0t0/HGRfvF3/fe699zGZJ4/rZUd4I/BJAQDgKAUAgKMUAACOUgAAOEoBAOBYc3Ha0OsVvvZVfUnKpW+/IsiuvbxMnk0XV8p8qqAnTerzrTJfuaI5DPP6a+T14JBZQv899+4L13mkEqXy7NxGPcVTvmChzJfpbymnr57aoS/wuWCW/nvWpMZl3tQYTnAtOydcq2FmNjmmp8BKqmfIfGJCX9ZTJF5iZkr/Q7S3H5b5nDPmyhynDj4pAAAcpQAAcJQCAMBRCgAARykAABy7j057eudO16GtQXaoNbxkxcwsGtou86ZZs2SezYzIvHV/eFnNWEaP9iSS+tKg5XP07zF9g4NBVpzVe5JWrdC7jLKRnhCK+y8SiZe494De5bTlVxMy/+/N3TJfc2F1kF139SJ5tq2nX+bTq/XfsySp3/OK4vDvuX98jjx75z0yths/fr3ML7vsMv0HcNLhkwIAwFEKAABHKQAAHKUAAHCUAgDAsfvoTap5Tjg51DRX78oZGz9f5vufe0DmpRWNMp+9dH2QVVTqfT75rN4JVF0TTuWYmSWGBoOsOf+gPFtI6x/7dKRve4ubz8uKC8wWL6qQZw9369vOltk8mb9tffi+DIYXo5mZWfMZemfTzx/RE0+jA/o2teJM+A02fERPUw2PhDfDmZndfdd3ZF5WHr7nay+4RJ7FicUnBQCAoxQAAI5SAAA4SgEA4HjQfJqITD9UjAqDMk8UwgeIHZ1H5NmtTz4k8wULZst86dkxDxBTeo2EVIi5Zaeg13YUVx8NsoG2Nnn2qc2LZT6v9lcyX7OoT+bJVPgEOubeIbvoIv1AfetBfbHRV38wGmRTOf2eLF40KPP3fnSdzI8O6DUk7T3hezgcc8nOREY/gG5u0BcbffELtwbZfQ/qn6uaqlqZ443BJwUAgKMUAACOUgAAOEoBAOAoBQCAY/ropKD2KOhVBFFOTxlNTerJoWQyI/PMeDjdsufl5+XZvgG9cuI9qy6WuRWldW5i1YO6qcbMLBEzxhNzQUz1tIYga92rL4i5ZL2ePnp6s76Upn+bvnxow4pdQZaK+6vHrMrIpfX00U03h6+x4Uw97WUJ/Z7E/e8uqtYrN+rnNQfZgd0H5dn2dj3BtGau/lmZHA9/nre9+JI8u+HicB0K3jh8UgAAOEoBAOAoBQCAoxQAAI5SAAA4po/eUHoEJTeyNciSMf8yUdykSUFPKxUKerpnbCy8UGUqq39HuPytl8o8FXNZTeyojZo0irvB5lXq7gz3E/3rt7fLs9d9KLxgyMzswgtXy/yXG8NJLTOzTC7crVSS0u/3A1v1TqD1i1pk3lgfvsbD5W/Rr6NYXzxUkdEX4VRMDcl8bDScHMqqm4TMLJnXPysxs2TWNDucnJojMpx4fFIAADhKAQDgKAUAgKMUAACOUgAAOKaPjgt9O9jA/kdkXlISTniU1oe7fMzMspmYnUhxLyVmt1AiWR5k7YfDiSQzs3UX18k8M6HPl5TpSRuLxCRL4tX+XqL/ptls+J73DeipobExvQ8qkYyZtEno9zCZKg6ydJE+O6da76yqaw73DZmZPZ5ZHmSDE03ybD6n3+9cVCLzC5NdMt/fvjfItvxa79QqTep/t0MtHTL/0B/eFGTNTfrvjhOLTwoAAEcpAAAcpQAAcJQCAMBRCgAAx/TR70RPq4wefEjm5YV+mXccDKdkzqio1N8yblon5qKyycmszH/yk3Df0owG/bVTMZMmhYKeBBru1RMo+Vw4OVVZO12ezeX0exvF7HKqqQoncP7p7z8hz1ZV6KmXx57U/2511QMyT5eEN7XlTb/fK5bqG9b6c+EUmJlZ72j496mIJuXZRE84NWRmlhk7LPMDJXoqq7h4RpC1v7hbnp1ZHk5emZntam+X+apzzw+yslL9nuDE4pMCAMBRCgAARykAABylAABwPGj+HUz075P57mc2ynx4eErmU8PhpSeDXZ3y7LLLL9Uvpkg/+Bsd1SsdWvbvCbJ3vuNt8mxnu35gWZZOy7ynI7x8xsysabpYu5DTqzJGR0ZkHhX0A+hcLnwAveNlvaKhkKyR+bSU/vd59zr9Gq0QPijNmb7wJqoMH0qbmVWk9IPmuVvD97B/rFWeXZTaJvPpC+fLfDjSQwz7Xw7/PSuK9KqM9tEemV/5wWtkvnDhQpnj5MMnBQCAoxQAAI5SAAA4SgEA4CgFAIBj+uiYhVMvh/c+LE8uOneJzAt5vaJB7ajIjOopm5GBozKvnjFP5j+879cyb2gM/+nTqZQ829vZK/OpCX1xTD6vX3vfYDhRtGx+hTxbVKRfS870e5jLh+sljnToCZmmWXoVxbJ5ehLIIr2OoWt0bpC1dM+UZ5vT22TeOE9PjV11Vvi+/OIXT8izDSv02o7G0lqZt27vk/m2X4TTTamU/r2xpEZPMP3+hz8q87hVKTj58C8FAHCUAgDAUQoAAEcpAAAcpQAAcEwfHaNdzz0aZNNr9CUz2ZzeoaNPmyXFxTlFpfrWnGQ6vHzFzKwQ6T1Eg4N6b08qF04O5ab0VE4+5sKbRMxESTpmYuVQV3hJzNEefSnL2vPDC1/MzFJF+ke2OB1OK1VVTZNnB/v0HqLthXAHlZlZQ9NimVc0vy/ImlP6/d7+0M9kvrJM/7tNb64Psve8a5082zesv+dt//yczJ97+qDMZzbVBlnc1FBVjd4flU7raSqcOvikAABwlAIAwFEKAABHKQAAHKUAAHBMHx2jlsMHgmzR1R+RZ6NJfUNWutAh8/Gj4Y6ebFZPpURldTL/6c9+KfNsZlTmSXFrWn5KT03lo7idTVohipmcSoWTKUe6c/LsQJ+eBKqt11MvkdgrVZ7Wr/v+h3bJfMFifVPZrPmNMl8+PbxlraGxVp7d0dsg876nxmS+em44lfXSXr33qmtIT/ycNUfvRBrt0rfaDY+G02cT4+HEmJlZ48xw75OZ2VRWT7Dh1MEnBQCAoxQAAI5SAAA4SgEA4HjQfIzUo9PObn1ZSX3TKplHtlzn08IH0+Wl+kHzpseflHnrAf3w9JJ158l8+/7wAe/QmP6eU1m9oEM/TjYbH8/IfGdLuI6hvkSfHRnWD0PLK/Saj0gsEVm2VD/cvXW2viAmKugH0/t27ZD50rOuCLJ0iX4QPjKlL/DpeOFFma85c06QLZmp13M8+VK3zBvG9EPfpum1Mu8fOBJkYzH/lmUjeoAhn9ODAzh18EkBAOAoBQCAoxQAAI5SAAA4SgEA4BJRFMXd/YLfcs893wmyugY9UbJ+/eUyTyT1sJdaI7H3hQfl2R/88GGZL1m6WuZDE3pap75xQfg1FoWZmVlfT7jiw8yss22rzEeG9KUvh0bE2oW8vsBnmr0g8yWzS2R+1sqFQZbL6kmYKBteMGRmlsnEXGCU0ZNQpdPXhK/vnKvl2Z6uAZn/8PtfkfnaM8PpniXz58mzqYpwUsnM7Mt33CfzkXG9WmNUvC37Duspo8995haZX/+xP5I5Th18UgAAOEoBAOAoBQCAoxQAAI5SAAA4dh8do3UX/16QPbHpfnk2m9EXxGSn9KTNo48+E2StLz0gzxZX6/1J2RJ96cn681fK/JxVZ8lc2deidwV1HDks89LKev09Z4fTR53derInmbhS5sMWXj5jZtZ1NNzENDReJs+2degf+0TMZUJnz9I7hPI924JsfOQyeba+Qe9EKiT1pUnfvT/ciXTLNfqyn6Wr9ETW2jPDS4DMzB7fHO44MjOrqAt/hhauXiLPMmV0+uKTAgDAUQoAAEcpAAAcpQAAcJQCAMCx++h3sHf/fpk//uQTMh8a6JX54EB/kH3gg9fKs9Ob9Z6bysoKmdfG5K+HfEFPU+VzOt+9J3y/vnPHt+TZm268UeYLY/YzFafDiaK4H+24H/iujjaZf/+ur8u8vPKMIPv4TZ+QZ6tr9CTQ2KDeE/Uf37szyHa/8Lw8e3HjPpmXVhTL/OnfHJJ5cfP8INsyKvZVmdlV73y/zP/4+o/JHKcOPikAABylAABwlAIAwFEKAABHKQAAHNNHx0E+5i0txNwylkyGe3tSydTr+ppOBuptmcpMyrMlpfoWtBMhM6lvKtv066eD7MK1F8izFZV6+ujV6O7ulPmtt3xS5ovL9Ht7aWM47WZmNpELb6rb8rw+27b07TL/t2+FNxTi1MInBQCAoxQAAI5SAAA4SgEA4HjQDJymurv0ZTqPffcvZb6gM7zYZ+PBUXm2fP0fyPzzf/rnx/jqcLLikwIAwFEKAABHKQAAHKUAAHCUAgDAMX0EvMns37ND5psfvTfIJkv0eo6rrrlB5g119a/5deHkwCcFAICjFAAAjlIAADhKAQDgKAUAgGP6CADg+KQAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHD/C4AbGNE/KsyiAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# These values would be obtained from your model's initialization, converted to numpy arrays\n",
    "betas = np.array(light_module.diff_model.betas.cpu().numpy())\n",
    "sqrt_recip_alphas = np.array(light_module.diff_model.sqrt_recip_alphas.cpu().numpy())\n",
    "sqrt_one_minus_alphas_cumprod = np.array(light_module.diff_model.sqrt_one_minus_alphas_cumprod.cpu().numpy())\n",
    "posterior_variance = np.array(light_module.diff_model.posterior_variance.cpu().numpy())\n",
    "\n",
    "num_timesteps = light_module.diff_model.num_timesteps\n",
    "img_shape = (1, 3, light_module.diff_model.image_size, light_module.diff_model.image_size)\n",
    "\n",
    "generated_images = p_sample_loop(ort_session, img_shape, betas, sqrt_recip_alphas, sqrt_one_minus_alphas_cumprod, posterior_variance, num_timesteps)\n",
    "\n",
    "# Save or display the generated image\n",
    "\n",
    "# Assuming `generated_images` is the output from the p_sample_loop\n",
    "# If necessary, move the tensor to CPU and convert it to numpy\n",
    "image = generated_images.squeeze().detach().cpu().numpy()\n",
    "\n",
    "# If the image is in [-1, 1], unnormalize it to [0, 1]\n",
    "image = (image + 1) / 2\n",
    "\n",
    "# Transpose the image to (H, W, C) if necessary (from (C, H, W))\n",
    "image = np.transpose(image, (1, 2, 0))\n",
    "\n",
    "# Display the image\n",
    "plt.imshow(image)\n",
    "plt.axis('off')  # Hide axes for better display\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "\n",
    "# Assuming betas, sqrt_recip_alphas, sqrt_one_minus_alphas_cumprod, and posterior_variance are numpy arrays\n",
    "\n",
    "data = {\n",
    "    \"betas\": betas.tolist(),\n",
    "    \"sqrt_recip_alphas\": sqrt_recip_alphas.tolist(),\n",
    "    \"sqrt_one_minus_alphas_cumprod\": sqrt_one_minus_alphas_cumprod.tolist(),\n",
    "    \"posterior_variance\": posterior_variance.tolist()\n",
    "}\n",
    "\n",
    "# Save as a JSON file\n",
    "with open('web-app/diffusion_buffers.json', 'w') as json_file:\n",
    "    json.dump(data, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
